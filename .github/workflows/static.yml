# Simple workflow for deploying static content to GitHub Pages
name: Deploy static content to Pages

on:
  # Runs on pushes targeting the default branch
  push:
    branches: ["main"]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages
permissions:
  contents: read
  pages: write
  id-token: write

# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.
# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.
concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  # Single deploy job since we're just deploying
  deploy:
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Generate meta.json
        run: |
          python3 -c "
          from pathlib import Path
          import json

          output_root = Path('output')
          manuals = []
          tag_definitions = {}

          for folder in sorted(output_root.iterdir()):
              if not folder.is_dir():
                  continue
              json_path = folder / 'translations.json'
              if not json_path.exists():
                  continue

              try:
                  with open(json_path, 'r', encoding='utf-8') as f:
                      data = json.load(f)

                  meta = data.get('meta', {})
                  pages = data.get('pages', [])
                  thumbnail = pages[0]['image'] if pages else 'pages/page-0.webp'

                  manual_info = {
                      'name': folder.name,
                      'source': meta.get('source', folder.name),
                      'pages': len(pages),
                      'blocks': sum(len(p.get('blocks', [])) for p in pages),
                      'thumbnail': f'{folder.name}/{thumbnail}',
                      'source_url': meta.get('source_url', ''),
                  }

                  if 'tags' in meta:
                      manual_info['tags'] = meta['tags']

                  if not tag_definitions and 'tag_definitions' in meta:
                      tag_definitions = meta['tag_definitions']

                  manuals.append(manual_info)
              except Exception as e:
                  print(f'Warning: Could not read {json_path}: {e}')

          meta_data = {
              'manuals': manuals,
              'tags': tag_definitions,
              'stats': {
                  'total_manuals': len(manuals),
                  'total_pages': sum(m['pages'] for m in manuals),
                  'total_blocks': sum(m['blocks'] for m in manuals)
              }
          }

          meta_path = output_root / 'meta.json'
          with open(meta_path, 'w', encoding='utf-8') as f:
              json.dump(meta_data, f, ensure_ascii=False, indent=2)

          print(f'✅ Generated meta.json with {len(manuals)} manuals, {len(tag_definitions)} tag types')
          "

      - name: Setup Pages
        uses: actions/configure-pages@v5

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: 'output'

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

      - name: Purge Cloudflare Cache
        if: success()
        run: |
          # Get list of changed files
          CHANGED_FILES=$(git diff --name-only ${{ github.event.before }} ${{ github.sha }} | grep '^output/' || echo "")

          if [ -z "$CHANGED_FILES" ]; then
            echo "No output files changed, skipping cache purge"
            exit 0
          fi

          # Convert file paths to URLs
          URLS=""
          while IFS= read -r file; do
            if [ ! -z "$file" ]; then
              # Remove 'output/' prefix and construct URL
              URL_PATH="${file#output/}"
              URLS="$URLS\"https://toku.solutions/$URL_PATH\","
            fi
          done <<< "$CHANGED_FILES"

          # Remove trailing comma
          URLS="${URLS%,}"

          if [ -z "$URLS" ]; then
            echo "No valid URLs to purge"
            exit 0
          fi

          # Purge specific files from Cloudflare
          echo "Purging Cloudflare cache for changed files..."
          curl -X POST "https://api.cloudflare.com/client/v4/zones/${{ secrets.CLOUDFLARE_ZONE_ID }}/purge_cache" \
            -H "Authorization: Bearer ${{ secrets.CLOUDFLARE_API_TOKEN }}" \
            -H "Content-Type: application/json" \
            --data "{\"files\":[$URLS]}"

          echo "✅ Cloudflare cache purged for changed files"
